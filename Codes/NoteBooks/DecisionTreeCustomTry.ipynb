{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "going-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-skill",
   "metadata": {},
   "source": [
    "# Try to write decision tree from scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "voluntary-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifierCustom():\n",
    "    # Init function that takes parameters\n",
    "    def __init__(self,criterion=\"gini\",prune='depth',max_depth=4,min_criterion=0.05):\n",
    "        self.feature=None\n",
    "        self.label=None\n",
    "        self.n_sample=None\n",
    "        self.gain=None\n",
    "        self.left=None\n",
    "        self.right=None\n",
    "        self.threshold = None\n",
    "        self.depth = 0\n",
    "\n",
    "        self.root = None\n",
    "        self.criterion = criterion\n",
    "        self.prune = prune\n",
    "        self.max_depth = max_depth\n",
    "        self.min_criterion = min_criterion\n",
    "    \n",
    "    #create the fit methid    \n",
    "    def fit(self, features, target):\n",
    "        self.root = DecisionTreeClassifierCustom()\n",
    "        self.root._grow_tree(features, target, self.criterion)\n",
    "        self.root._prune(self.prune, self.max_depth, self.min_criterion, self.root.n_samples)\n",
    "\n",
    "    #predict after traversing the tree\n",
    "    def predict(self, features):\n",
    "        return np.array([self.root._predict(f) for f in features])\n",
    "\n",
    "    def print_tree(self):\n",
    "        self.root._show_tree(0, ' ')\n",
    "\n",
    "    def _grow_tree(self, features, target, criterion = 'gini'):\n",
    "        self.n_samples = features.shape[0] \n",
    "\n",
    "        if len(np.unique(target)) == 1:\n",
    "            self.label = target[0]\n",
    "            return\n",
    "\n",
    "        best_gain = 0.0\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        if criterion in {'gini', 'entropy'}:\n",
    "            self.label = max([(c, len(target[target == c])) for c in np.unique(target)], key = lambda x : x[1])[0]\n",
    "\n",
    "        impurity_node = self._calc_impurity(criterion, target)\n",
    "        \n",
    "        for col in range(features.shape[1]):\n",
    "            feature_level = np.unique(features[:,col])\n",
    "            thresholds = (feature_level[:-1] + feature_level[1:]) / 2.0\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                target_l = target[features[:,col] <= threshold]\n",
    "                impurity_l = self._calc_impurity(criterion, target_l)\n",
    "                n_l = float(target_l.shape[0]) / self.n_samples\n",
    "\n",
    "                target_r = target[features[:,col] > threshold]\n",
    "                impurity_r = self._calc_impurity(criterion, target_r)\n",
    "                n_r = float(target_r.shape[0]) / self.n_samples\n",
    "\n",
    "                impurity_gain = impurity_node - (n_l * impurity_l + n_r * impurity_r)\n",
    "                if impurity_gain > best_gain:\n",
    "                    best_gain = impurity_gain\n",
    "                    best_feature = col\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        self.feature = best_feature\n",
    "        self.gain = best_gain\n",
    "        self.threshold = best_threshold\n",
    "        self._split_tree(features, target, criterion)\n",
    "    \n",
    "    def _split_tree(self, features, target, criterion):\n",
    "        features_l = features[features[:, self.feature] <= self.threshold]\n",
    "        target_l = target[features[:, self.feature] <= self.threshold]\n",
    "        self.left = DecisionTreeClassifierCustom()\n",
    "        self.left.depth = self.depth + 1\n",
    "        self.left._grow_tree(features_l, target_l, criterion)\n",
    "\n",
    "        features_r = features[features[:, self.feature] > self.threshold]\n",
    "        target_r = target[features[:, self.feature] > self.threshold]\n",
    "        self.right = DecisionTreeClassifierCustom()\n",
    "        self.right.depth = self.depth + 1\n",
    "        self.right._grow_tree(features_r, target_r, criterion)    \n",
    "   \n",
    "    def _calc_impurity(self, criterion, target):\n",
    "        if criterion == 'gini':\n",
    "            return 1.0 - sum([(float(len(target[target == c])) / float(target.shape[0])) ** 2.0 for c in np.unique(target)])\n",
    "        elif criterion == 'mse':\n",
    "            return np.mean((target - np.mean(target)) ** 2.0)\n",
    "        else:\n",
    "            entropy = 0.0\n",
    "            for c in np.unique(target):\n",
    "                p = float(len(target[target == c])) / target.shape[0]\n",
    "                if p > 0.0:\n",
    "                    entropy -= p * np.log2(p)\n",
    "            return entropy            \n",
    "\n",
    "    def _prune(self, method, max_depth, min_criterion, n_samples):\n",
    "        if self.feature is None:\n",
    "            return\n",
    "\n",
    "        self.left._prune(method, max_depth, min_criterion, n_samples)\n",
    "        self.right._prune(method, max_depth, min_criterion, n_samples)\n",
    "\n",
    "        pruning = False\n",
    "\n",
    "        if method == 'impurity' and self.left.feature is None and self.right.feature is None: \n",
    "            if (self.gain * float(self.n_samples) / n_samples) < min_criterion:\n",
    "                pruning = True\n",
    "        elif method == 'depth' and self.depth >= max_depth:\n",
    "            pruning = True\n",
    "\n",
    "        if pruning is True:\n",
    "            self.left = None\n",
    "            self.right = None\n",
    "            self.feature = None\n",
    "\n",
    "    def _predict(self, d):\n",
    "        if self.feature != None:\n",
    "            if d[self.feature] <= self.threshold:\n",
    "                return self.left._predict(d)\n",
    "            else:\n",
    "                return self.right._predict(d)\n",
    "        else: \n",
    "            return self.label\n",
    "\n",
    "    def _show_tree(self, depth, cond):\n",
    "        base = '    ' * depth + cond\n",
    "        if self.feature != None:\n",
    "            print(base + 'if X[' + str(self.feature) + '] <= ' + str(self.threshold))\n",
    "            self.left._show_tree(depth+1, 'then ')\n",
    "            self.right._show_tree(depth+1, 'else ')\n",
    "        else:\n",
    "            print(base + '{value: ' + str(self.label) + ', samples: ' + str(self.n_samples) + '}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "healthy-scene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Classification Tree\n",
      " if X[2] <= 2.45\n",
      "    then {value: 0, samples: 35}\n",
      "    else if X[2] <= 4.75\n",
      "        then if X[3] <= 1.65\n",
      "            then {value: 1, samples: 34}\n",
      "            else {value: 2, samples: 1}\n",
      "        else if X[2] <= 5.15\n",
      "            then {value: 2, samples: 16}\n",
      "            else {value: 2, samples: 26}\n",
      "This Classification Tree Prediction Accuracy:    0.9736842105263158\n",
      "Sklearn Library Tree Prediction Accuracy:        0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree as sktree\n",
    "\n",
    "def classification_example():\n",
    "    print('\\n\\nClassification Tree')\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "    cls = DecisionTreeClassifierCustom(criterion = 'entropy', prune = 'depth', max_depth = 3)\n",
    "    cls.fit(X_train, y_train)\n",
    "    cls.print_tree()\n",
    "\n",
    "    pred = cls.predict(X_test)\n",
    "    print(\"This Classification Tree Prediction Accuracy:    {}\".format(sum(pred == y_test) / len(pred)))\n",
    "\n",
    "    clf = sktree.DecisionTreeClassifier(criterion = 'entropy')\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    sk_pred = clf.predict(X_test)\n",
    "\n",
    "    print(\"Sklearn Library Tree Prediction Accuracy:        {}\".format(sum(sk_pred == y_test) / len(pred)))\n",
    "\n",
    "\n",
    "classification_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-grain",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
